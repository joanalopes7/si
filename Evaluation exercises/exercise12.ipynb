{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento:\n",
      "Entrada:\n",
      "[[ 0.11551678 -2.18033755 -0.20558071]\n",
      " [-1.36485281 -1.53388933 -0.48920917]\n",
      " [ 0.07214588  1.04042433 -0.90363809]]\n",
      "Saída com Dropout:\n",
      "[[ 0.         -4.36067509 -0.        ]\n",
      " [-2.72970562 -3.06777865 -0.97841834]\n",
      " [ 0.14429176  2.08084867 -0.        ]]\n",
      "Máscara aplicada:\n",
      "[[0 1 0]\n",
      " [1 1 1]\n",
      " [1 1 0]]\n",
      "\n",
      "Inferência:\n",
      "Entrada:\n",
      "[[ 0.11551678 -2.18033755 -0.20558071]\n",
      " [-1.36485281 -1.53388933 -0.48920917]\n",
      " [ 0.07214588  1.04042433 -0.90363809]]\n",
      "Saída com Dropout (sem alteração):\n",
      "[[ 0.11551678 -2.18033755 -0.20558071]\n",
      " [-1.36485281 -1.53388933 -0.48920917]\n",
      " [ 0.07214588  1.04042433 -0.90363809]]\n"
     ]
    }
   ],
   "source": [
    "from si.neural_networks.layers import Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento:\n",
      "Entrada:\n",
      "[[ 0.80751739 -1.04174609  0.41735442]\n",
      " [-0.21362786 -0.41399812 -1.62113164]\n",
      " [ 1.01183818  0.21971938 -1.62029227]]\n",
      "Saída com Dropout:\n",
      "[[ 0.         -0.          0.83470884]\n",
      " [-0.42725571 -0.82799624 -0.        ]\n",
      " [ 2.02367636  0.         -0.        ]]\n",
      "Máscara aplicada:\n",
      "[[0 0 1]\n",
      " [1 1 0]\n",
      " [1 0 0]]\n",
      "\n",
      "Inferência:\n",
      "Entrada:\n",
      "[[ 0.80751739 -1.04174609  0.41735442]\n",
      " [-0.21362786 -0.41399812 -1.62113164]\n",
      " [ 1.01183818  0.21971938 -1.62029227]]\n",
      "Saída com Dropout (sem alteração):\n",
      "[[ 0.80751739 -1.04174609  0.41735442]\n",
      " [-0.21362786 -0.41399812 -1.62113164]\n",
      " [ 1.01183818  0.21971938 -1.62029227]]\n"
     ]
    }
   ],
   "source": [
    "probability = 0.5  # Taxa de dropout (50%)\n",
    "input_data = np.random.randn(3, 3)  # Entrada aleatória (3x3)\n",
    "\n",
    "# Criação da camada Dropout\n",
    "dropout_layer = Dropout(probability=probability)\n",
    "\n",
    "# Teste durante o treinamento\n",
    "print(\"Treinamento:\")\n",
    "output_train = dropout_layer.forward_propagation(input_data, training=True)\n",
    "print(\"Entrada:\")\n",
    "print(input_data)\n",
    "print(\"Saída com Dropout:\")\n",
    "print(output_train)\n",
    "print(\"Máscara aplicada:\")\n",
    "print(dropout_layer.mask)\n",
    "\n",
    "# Teste durante a inferência (sem dropout)\n",
    "print(\"\\nInferência:\")\n",
    "output_infer = dropout_layer.forward_propagation(input_data, training=False)\n",
    "print(\"Entrada:\")\n",
    "print(input_data)\n",
    "print(\"Saída com Dropout (sem alteração):\")\n",
    "print(output_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função tem a saíde esperada. Conseguimos vez que após a aplicação da máscara, durante o treino a saída passa a ter neurónios desativados (0) e ativados, enquanto que no processo de inferência isso não acontece.\n",
    "Os tamanhos das entradas e saídas são iguais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joanasib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
